{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import unicodedata\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "import nltk.sentiment\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from time import strftime\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "\n",
    "plt.rc('figure', figsize=(13, 7))\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "\n",
    "from prepare import basic_clean, lemmatize\n",
    "import prepare_spam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import spam data\n",
    "\n",
    "df = pd.read_csv('spam_clean.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare spam data\n",
    "\n",
    "df.rename(columns={'text': 'original'}, inplace=True)\n",
    "df = prepare_spam.prep_article_data(df, 'original', extra_words = ['u', '2', 'ur', \"'\", '4'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make word lists\n",
    "lemmatized_ham_words =(' '.join(df[df.label == 'ham'].lemmatized))\n",
    "lemmatized_spam_words =(' '.join(df[df.label == 'spam'].lemmatized))\n",
    "lemmatized_all_words = (' '.join(df.lemmatized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at frequency\n",
    "lemmatized_ham_freq = pd.Series(lemmatized_ham_words.split()).value_counts()\n",
    "lemmatized_spam_freq = pd.Series(lemmatized_spam_words.split()).value_counts()\n",
    "lemmatized_all_freq = pd.Series(lemmatized_all_words.split()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>call</th>\n",
       "      <td>600</td>\n",
       "      <td>241</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>397</td>\n",
       "      <td>314</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>304</td>\n",
       "      <td>273</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>277</td>\n",
       "      <td>272</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ltgt</th>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>275</td>\n",
       "      <td>59</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>267</td>\n",
       "      <td>241</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>252</td>\n",
       "      <td>225</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>247</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>245</td>\n",
       "      <td>232</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>238</td>\n",
       "      <td>231</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>235</td>\n",
       "      <td>223</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wa</th>\n",
       "      <td>234</td>\n",
       "      <td>225</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>232</td>\n",
       "      <td>213</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>214</td>\n",
       "      <td>77</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>213</td>\n",
       "      <td>183</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>204</td>\n",
       "      <td>194</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>send</th>\n",
       "      <td>190</td>\n",
       "      <td>123</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>182</td>\n",
       "      <td>171</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>180</td>\n",
       "      <td>170</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      all  ham  spam\n",
       "call  600  241   359\n",
       "get   397  314    83\n",
       "go    304  273    31\n",
       "ok    277  272     5\n",
       "ltgt  276  276     0\n",
       "free  275   59   216\n",
       "know  267  241    26\n",
       "day   252  225    27\n",
       "come  247  242     5\n",
       "like  245  232    13\n",
       "got   238  231     7\n",
       "good  235  223    12\n",
       "wa    234  225     9\n",
       "time  232  213    19\n",
       "text  214   77   137\n",
       "want  213  183    30\n",
       "love  204  194    10\n",
       "send  190  123    67\n",
       "need  182  171    11\n",
       "one   180  170    10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at top 20 words\n",
    "word_counts = (pd.concat([lemmatized_all_freq, lemmatized_ham_freq, lemmatized_spam_freq], axis=1, sort=True)\n",
    "                .set_axis(['all', 'ham', 'spam'], axis=1, inplace=False)\n",
    "                .fillna(0)\n",
    "                .apply(lambda s: s.astype(int)))\n",
    "\n",
    "word_counts.sort_values(by='all', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham    0.865937\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish baseline - ham mode\n",
    "\n",
    "df[df['label']=='ham'].label.value_counts()/sum(df.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split XY and vectorize\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.lemmatized)\n",
    "y = df.label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create evaluation dataframe\n",
    "train_eval = pd.DataFrame(dict(actual=y_train))\n",
    "train_eval['baseline']='ham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "train_eval['gnb_predicted'] = gnb.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.53%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual          ham  spam\n",
      "gnb_predicted            \n",
      "ham            3615     0\n",
      "spam            244   598\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      0.94      0.97      3859\n",
      "        spam       0.71      1.00      0.83       598\n",
      "\n",
      "    accuracy                           0.95      4457\n",
      "   macro avg       0.86      0.97      0.90      4457\n",
      "weighted avg       0.96      0.95      0.95      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_eval.actual, train_eval.gnb_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train_eval.gnb_predicted, train_eval.actual))\n",
    "print('---')\n",
    "print(classification_report(train_eval.actual, train_eval.gnb_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8867713 , 0.90134529, 0.89450056, 0.88215488, 0.88103255])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(gnb, X_train, y_train, cv = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.58%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "baseline            \n",
      "ham       3859   598\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      1.00      0.93      3859\n",
      "        spam       0.00      0.00      0.00       598\n",
      "\n",
      "    accuracy                           0.87      4457\n",
      "   macro avg       0.43      0.50      0.46      4457\n",
      "weighted avg       0.75      0.87      0.80      4457\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Baseline eval\n",
    "# Calculate baseline model performance\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_eval.actual, train_eval.baseline)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train_eval.baseline, train_eval.actual))\n",
    "print('---')\n",
    "print(classification_report(train_eval.actual, train_eval.baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_eval.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>baseline</th>\n",
       "      <th>gnb_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4620</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4143</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual baseline gnb_predicted\n",
       "4620    ham      ham           ham\n",
       "4143    ham      ham           ham\n",
       "576     ham      ham           ham\n",
       "239    spam      ham          spam\n",
       "2103    ham      ham           ham"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.48%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         ham  spam\n",
      "lm_predicted            \n",
      "ham           3852   150\n",
      "spam             7   448\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98      3859\n",
      "        spam       0.98      0.75      0.85       598\n",
      "\n",
      "    accuracy                           0.96      4457\n",
      "   macro avg       0.97      0.87      0.92      4457\n",
      "weighted avg       0.97      0.96      0.96      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression model\n",
    "\n",
    "# Make and fit the object\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Use it to make predictions\n",
    "train['lm_predicted'] = lm.predict(X_train)\n",
    "# Asssess accuracy\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.lm_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.lm_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.lm_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9338565 , 0.94058296, 0.95286195, 0.9382716 , 0.93602694])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lm, X_train, y_train, cv = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.87%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         ham  spam\n",
      "dt_predicted            \n",
      "ham           3834   293\n",
      "spam            25   305\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      0.99      0.96      3859\n",
      "        spam       0.92      0.51      0.66       598\n",
      "\n",
      "    accuracy                           0.93      4457\n",
      "   macro avg       0.93      0.75      0.81      4457\n",
      "weighted avg       0.93      0.93      0.92      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision tree model\n",
    "# Make and fit the object\n",
    "dtc = DecisionTreeClassifier(max_depth = 2).fit(X_train, y_train)\n",
    "# Use the object\n",
    "train['dt_predicted'] = dtc.predict(X_train)\n",
    "# Determine performance\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.dt_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.dt_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.dt_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92825112, 0.9293722 , 0.93378227, 0.92480359, 0.92031425])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(dtc, X_train, y_train, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.70%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         ham  spam\n",
      "rf_predicted            \n",
      "ham           3859   548\n",
      "spam             0    50\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.88      1.00      0.93      3859\n",
      "        spam       1.00      0.08      0.15       598\n",
      "\n",
      "    accuracy                           0.88      4457\n",
      "   macro avg       0.94      0.54      0.54      4457\n",
      "weighted avg       0.89      0.88      0.83      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "# Make and fit object\n",
    "rf = RandomForestClassifier(bootstrap = True, \n",
    "                            class_weight = None, \n",
    "                            criterion = 'gini',\n",
    "                            min_samples_leaf = 3,\n",
    "                            n_estimators = 100,\n",
    "                            max_depth = 8, \n",
    "                            random_state = 123).fit(X_train, y_train)\n",
    "# Use it to make predictions\n",
    "train['rf_predicted'] = rf.predict(X_train)\n",
    "# Assess performance\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.rf_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.rf_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.rf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87668161, 0.87780269, 0.87991021, 0.87429854, 0.87542088])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf, X_train, y_train, cv = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.32%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual          ham  spam\n",
      "knn_predicted            \n",
      "ham            3859   387\n",
      "spam              0   211\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.91      1.00      0.95      3859\n",
      "        spam       1.00      0.35      0.52       598\n",
      "\n",
      "    accuracy                           0.91      4457\n",
      "   macro avg       0.95      0.68      0.74      4457\n",
      "weighted avg       0.92      0.91      0.89      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# Make and fit the object\n",
    "knn = KNeighborsClassifier(n_neighbors = 4).fit(X_train, y_train)\n",
    "# Use the object \n",
    "train['knn_predicted'] = knn.predict(X_train)\n",
    "# Evaluate performance\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.knn_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.knn_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.knn_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score(knn, X_train, y_train, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.96%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual          ham  spam\n",
      "svc_predicted            \n",
      "ham            3858     1\n",
      "spam              1   597\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00      3859\n",
      "        spam       1.00      1.00      1.00       598\n",
      "\n",
      "    accuracy                           1.00      4457\n",
      "   macro avg       1.00      1.00      1.00      4457\n",
      "weighted avg       1.00      1.00      1.00      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "# Make and fit the object\n",
    "svc = LinearSVC(random_state=0).fit(X_train, y_train)\n",
    "# Use the object\n",
    "train['svc_predicted'] = svc.predict(X_train)\n",
    "# Evaluate model\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.svc_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.svc_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.svc_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97309417, 0.97869955, 0.97755331, 0.97643098, 0.96969697])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svc, X_train, y_train, cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEst best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.67%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         ham  spam\n",
      "svc_predicted           \n",
      "ham            964    24\n",
      "spam             2   125\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       966\n",
      "        spam       0.98      0.84      0.91       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.92      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create testing dataframe\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "test['svc_predicted'] = svc.predict(X_test)\n",
    "# Evaluate model\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.svc_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.svc_predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.svc_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12835027726432532"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(97.67-86.56)/86.56"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC performs well on in and out of sample data.\n",
    "\n",
    "98% accurate - 13% improvement from baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
